import requests
import json
import time
import os
import sys
from pathlib import Path

from db_manager import DatabaseManager
from naver_book_api import NaverBookAPI
# ìƒìœ„ ë””ë ‰í† ë¦¬ì— ìˆëŠ” bookinfo ëª¨ë“ˆì„ import í•˜ê¸° ìœ„í•œ ì„¤ì •
# sys.path.append(str(Path(__file__).parent.parent))
from main import KyoboBookScraper

# scraper = KyoboBookScraper()

naver_api = NaverBookAPI(
            client_id="Ify9yiAgxNVLZrnrF7pV",
            client_secret="Svz3ireH_a"
        )

db = DatabaseManager(
    host='wordplayapi.mycafe24.com',
    user='wordplayapi',
    password='Hazbola2021!',
    db='wordplayapi'
)

def fetch_kyobo_bestsellers(page=1, per_page=50):
    url = f"https://store.kyobobook.co.kr/api/gw/best/best-seller/online?page={page}&per=50&period=003&dsplDvsnCode=001&ymw=202405&dsplTrgtDvsnCode=004&saleCmdtClstCode=42"
    try:
        response = requests.get(url)
        response.raise_for_status()
        return response.json()
    except requests.exceptions.RequestException as e:
        print(f"Error fetching data from page {page}: {e}")
        return None


def process_single_book(book, scraper):
    # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
    processed_book = {
        'kyobo_id': book.get('saleCmdtid', ''),
        'isbn': book.get('cmdtCode', ''),
        'title': book.get('cmdtName', '')
    }

    # ë„ì„œ ìƒì„¸ URL ìƒì„±
    book_url = f"https://product.kyobobook.co.kr/detail/{processed_book['kyobo_id']}"
    print(f"Processing book: {processed_book['title']} ({book_url})")

    try:
        # ê¸°ë³¸ ì •ë³´ ì €ì¥
        book_data = {
            'kyobo_id': processed_book['kyobo_id'],
            'isbn': processed_book['isbn'],
            'title': processed_book['title']
        }

        insert_result = db.insert_book(book_data)
        if insert_result:
            print(f"âœ… ê¸°ë³¸ ì •ë³´ ì €ì¥ ì™„ë£Œ: {processed_book['title']}")

            # ë„¤ì´ë²„ APIì—ì„œ ì¶”ê°€ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            isbn_list = [processed_book['isbn']]
            results = naver_api.search_multiple_isbns(isbn_list)

            update_success = False
            for isbn, info in results.items():
                if info:
                    book_data = {
                        'author': info['author'],
                        'publisher': info['publisher'],
                        'publication_date': info['pubdate'],
                        'kyobo_id': processed_book['kyobo_id']
                    }

                    # ë„¤ì´ë²„ ì •ë³´ë¡œ ì—…ë°ì´íŠ¸
                    update_success = db.update_book_info(book_data)
                    if update_success:
                        print(f"âœ… ë„¤ì´ë²„ ì •ë³´ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {processed_book['title']}")
                    else:
                        print(f"âŒ ë„¤ì´ë²„ ì •ë³´ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {processed_book['title']}")
                else:
                    print(f"ISBN {isbn}: ë„¤ì´ë²„ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")

            # ë„¤ì´ë²„ ì—…ë°ì´íŠ¸ê°€ ì„±ê³µí•˜ê±°ë‚˜ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš°ì—ë§Œ ìŠ¤í¬ë˜í¼ ì‹¤í–‰
            if update_success or not results.get(processed_book['isbn']):
                print(f"ğŸ” êµë³´ë¬¸ê³ ì—ì„œ ìƒì„¸ ì •ë³´ ìŠ¤í¬ë˜í•‘ ì‹œì‘: {processed_book['title']}")
                book_details = scraper.scrape(book_url)

                if book_details:
                    print(f"âœ… êµë³´ë¬¸ê³  ìƒì„¸ ì •ë³´ ìŠ¤í¬ë˜í•‘ ì™„ë£Œ: {processed_book['title']}")

                    print(" [ book_details ] ", book_details )

                    # book_detailsì— kyobo_id ì¶”ê°€ (ì—…ë°ì´íŠ¸ì— í•„ìš”)
                    book_details['kyobo_id'] = processed_book['kyobo_id']

                    # ìŠ¤í¬ë˜í•‘í•œ ìƒì„¸ ì •ë³´ë¡œ ë‹¤ì‹œ ì—…ë°ì´íŠ¸
                    if db.update_book(book_details):
                        print(f"âœ… êµë³´ë¬¸ê³  ìƒì„¸ ì •ë³´ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {processed_book['title']}")
                    else:
                        print(f"âŒ êµë³´ë¬¸ê³  ìƒì„¸ ì •ë³´ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {processed_book['title']}")

                    # processed_book ê°ì²´ì— ìƒì„¸ ì •ë³´ ë³‘í•©
                    processed_book.update(book_details)
                else:
                    print(f"âŒ êµë³´ë¬¸ê³  ìƒì„¸ ì •ë³´ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {processed_book['title']}")
        else:
            print(f"â„¹ï¸ ì´ë¯¸ ë°ì´í„°ë² ì´ìŠ¤ì— ì¡´ì¬í•˜ëŠ” ë„ì„œ: {processed_book['title']}")

        print(f"âœ… ì²˜ë¦¬ ì™„ë£Œ: {processed_book['title']}")

    except Exception as e:
        print(f"âŒ ë„ì„œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {processed_book['title']}: {e}")

    # í¬ë¡¤ë§ ê°„ ê°„ê²©ì„ ë‘ì–´ ì„œë²„ì— ë¶€ë‹´ì„ ì¤„ì…ë‹ˆë‹¤
    time.sleep(2)

    return processed_book


def save_state(current_page, current_book_index, processed_data):
    state = {
        'current_page': current_page,
        'current_book_index': current_book_index,
        'last_updated': time.strftime('%Y-%m-%d %H:%M:%S')
    }

    # ìƒíƒœ íŒŒì¼ ì €ì¥
    with open('crawler_state.json', 'w', encoding='utf-8') as f:
        json.dump(state, f, ensure_ascii=False, indent=2)

    # ì§€ê¸ˆê¹Œì§€ ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥
    with open('kyobo_bestsellers_partial.json', 'w', encoding='utf-8') as f:
        json.dump(processed_data, f, ensure_ascii=False, indent=2)

    print(f"Saved state: Page {current_page}, Book {current_book_index}")


def load_state():
    if os.path.exists('crawler_state.json'):
        try:
            with open('crawler_state.json', 'r', encoding='utf-8') as f:
                state = json.load(f)

            # ì´ì „ì— ì €ì¥ëœ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
            if os.path.exists('kyobo_bestsellers_partial.json'):
                with open('kyobo_bestsellers_partial.json', 'r', encoding='utf-8') as f:
                    processed_data = json.load(f)
            else:
                processed_data = []

            print(
                f"Loaded state: Page {state['current_page']}, Book {state['current_book_index']}, Last updated: {state['last_updated']}")
            return state['current_page'], state['current_book_index'], processed_data
        except Exception as e:
            print(f"Error loading state: {e}")

    # ìƒíƒœ íŒŒì¼ì´ ì—†ê±°ë‚˜ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ ì²˜ìŒë¶€í„° ì‹œì‘
    return 1, 0, []


def process_all_pages(max_pages=5, resume=True):
    # KyoboBookScraper ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    scraper = KyoboBookScraper()

    # ìƒíƒœ ë¡œë“œ (ì´ì–´ì„œ ì‹œì‘í• ì§€ ì—¬ë¶€ì— ë”°ë¼)
    if resume:
        current_page, current_book_index, all_processed_data = load_state()
    else:
        current_page, current_book_index, all_processed_data = 1, 0, []

    try:
        # ì§€ì •ëœ í˜ì´ì§€ë¶€í„° ìµœëŒ€ í˜ì´ì§€ê¹Œì§€ ì²˜ë¦¬
        for page in range(current_page, max_pages + 1):
            print(f"\n{'=' * 50}")
            print(f"Processing page {page}...")
            print(f"{'=' * 50}\n")

            raw_data = fetch_kyobo_bestsellers(page)

            if not raw_data or 'data' not in raw_data or 'bestSeller' not in raw_data['data']:
                print(f"No valid data found on page {page}. Stopping.")
                save_state(page + 1, 0, all_processed_data)  # ë‹¤ìŒ í˜ì´ì§€ë¶€í„° ì‹œì‘í•˜ë„ë¡ ì €ì¥
                break

            books = raw_data['data']['bestSeller']
            if not books:
                print(f"No books found on page {page}. Stopping.")
                save_state(page + 1, 0, all_processed_data)  # ë‹¤ìŒ í˜ì´ì§€ë¶€í„° ì‹œì‘í•˜ë„ë¡ ì €ì¥
                break

            print(f"Found {len(books)} books on page {page}")

            # ì´ í˜ì´ì§€ì—ì„œ ì‹œì‘í•  ì±… ì¸ë±ìŠ¤ ê²°ì •
            start_book_index = current_book_index if page == current_page else 0

            # ê° ì±…ì„ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬
            for i, book in enumerate(books[start_book_index:], start_book_index + 1):
                try:
                    print(f"\n{'*' * 30}")
                    print(f"Processing book {i} of {len(books)} on page {page}")
                    print(f"{'*' * 30}")

                    processed_book = process_single_book(book, scraper)
                    all_processed_data.append(processed_book)

                    # ë§¤ ì±… ì²˜ë¦¬ í›„ ìƒíƒœ ì €ì¥
                    save_state(page, i, all_processed_data)

                except Exception as e:
                    print(f"Error processing book {i} on page {page}: {e}")
                    save_state(page, i, all_processed_data)  # ì˜¤ë¥˜ ë°œìƒ ì‹œ í˜„ì¬ ìƒíƒœ ì €ì¥
                    raise  # ì˜ˆì™¸ë¥¼ ë‹¤ì‹œ ë°œìƒì‹œì¼œ ì²˜ë¦¬ ì¤‘ë‹¨

            # í˜ì´ì§€ ì²˜ë¦¬ ì™„ë£Œ ì‹œ ìƒíƒœ ì €ì¥
            current_book_index = 0  # ë‹¤ìŒ í˜ì´ì§€ëŠ” ì²˜ìŒë¶€í„° ì‹œì‘
            save_state(page + 1, current_book_index, all_processed_data)

            # í˜ì´ì§€ ì²˜ë¦¬ ì™„ë£Œ ë©”ì‹œì§€
            print(f"\nCompleted processing page {page}. Total books processed so far: {len(all_processed_data)}")

            # í˜ì´ì§€ ê°„ ê°„ê²©
            if page < max_pages:
                print("Waiting before fetching next page...")
                time.sleep(5)

    except KeyboardInterrupt:
        print("\nProcess interrupted by user. Current state has been saved.")
        return all_processed_data
    except Exception as e:
        print(f"\nError occurred: {e}. Current state has been saved.")
        return all_processed_data

    # ëª¨ë“  í˜ì´ì§€ ì²˜ë¦¬ ì™„ë£Œ ì‹œ ìƒíƒœ íŒŒì¼ ì‚­ì œ
    if os.path.exists('crawler_state.json'):
        os.remove('crawler_state.json')
    if os.path.exists('kyobo_bestsellers_partial.json'):
        os.remove('kyobo_bestsellers_partial.json')

    return all_processed_data


def main():
    # ì²˜ë¦¬í•  ìµœëŒ€ í˜ì´ì§€ ìˆ˜ ì„¤ì •
    max_pages = 50

    # ì´ì–´ì„œ ì‹œì‘í• ì§€ ì—¬ë¶€ í™•ì¸
    resume = False
    if os.path.exists('crawler_state.json'):
        choice = input("Previous crawling state found. Resume? (y/n): ").lower()
        resume = choice == 'y' or choice == ''  # ì—”í„°í‚¤ë„ yesë¡œ ì²˜ë¦¬

    print(f"Starting to process up to {max_pages} pages of Kyobo bestsellers")
    processed_data = process_all_pages(max_pages, resume)

    if processed_data:
        print(f"\nTotal books processed across all pages: {len(processed_data)}")

        # ê²°ê³¼ ì €ì¥
        with open('kyobo_bestsellers_complete.json', 'w', encoding='utf-8') as f:
            json.dump(processed_data, f, ensure_ascii=False, indent=2)
        print("All data saved to kyobo_bestsellers_complete.json")
    else:
        print("No data was processed.")


if __name__ == "__main__":
    main()